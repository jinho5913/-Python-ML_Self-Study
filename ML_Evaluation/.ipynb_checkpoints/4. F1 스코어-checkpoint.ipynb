{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. F1 스코어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 스코어는 정밀도와 재현율을 결합한 지표이다**  \n",
    "F1 스코어는 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가진다  \n",
    "  \n",
    "<공식>  \n",
    "$$ F1 = \\frac{2}{(\\frac{1}{recall})+(\\frac{1}{precision})} = 2 * \\frac{precision * recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "# 오차 행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## 로지스틱 회귀 기반으로 타이타닉 생존자 예측 후 위의 평가 진행\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습/테스트 데이터 분할\n",
    "titanic = pd.read_csv('data_set/titanic_train.csv')\n",
    "y_titanic = titanic['Survived']\n",
    "X_titanic = titanic.drop('Survived', axis = 1)\n",
    "X_titanic = transform_features(X_titanic)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic, y_titanic,\n",
    "                                                   test_size = 0.2, random_state = 11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 스코어 : 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_test, pred)\n",
    "print('f1 스코어 : {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 임계값 별 F1 스코어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361, F1:0.7786\n",
      "\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033, F1:0.7840\n",
      "\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805\n",
      "\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541, F1:0.7931\n",
      "\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377, F1:0.8036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "        print('')\n",
    "\n",
    "    \n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
