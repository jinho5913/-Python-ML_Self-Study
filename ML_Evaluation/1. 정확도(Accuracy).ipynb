{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ 정확도(Accracy) =  \\frac{예측 결과가 동일한 데이터 건수}{전체 예측 데이터 건수}$$  \n",
    "**정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표이다.** 하지만 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 'titanic' 데이터 셋에서 ML 알고리즘을 적용한 후 예측 정확도의 결과가 보통 80%대 였지만 단지 성별 조건 하나만을 가지고 결정하는 별거 아닌 알고리즘도 높은 정확도를 나타내는 상황이 발생함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit() 메서드는 아무것도 학습하지 않음.\n",
    "    def fit(self, X, y = None):\n",
    "        pass\n",
    "    \n",
    "    # predict() 메서드는 단순이 Sex 피쳐가 1이면 0, 아니면 1로 예측함\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 :0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터 로딩, 데이터 가공, 학습/테스트 데이터 분할\n",
    "titanic = pd.read_csv('data_set/titanic_train.csv')\n",
    "y_titanic = titanic['Survived']\n",
    "X_titanic = titanic.drop('Survived', axis = 1)\n",
    "X_titanic = transform_features(X_titanic)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic, y_titanic,\n",
    "                                                   test_size = 0.2, random_state = 0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행\n",
    "my_clf = MyDummyClassifier()\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "my_prediction = my_clf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는 :{0:.4f}'.format(accuracy_score(y_test, my_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 단순한 알고리즘으로 예측을 하더라도 데이터의 구성에 따라 정확도의 약 78.77\n",
    "%로 꽤 높은 수치가 나올 수 있다  \n",
    "따라서 정확도를 평가 지표로 사용할 경우 매우 신중해야 한다  \n",
    "특히 **정확도**는 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 평가 지표가 아니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0 값으로 만들어서 반환\n",
    "    def predict(sel, X):\n",
    "        return np.zeros((len(X),1), dtype = bool)\n",
    "    \n",
    "# 사이킷런의 내장 데이터 셋인 load_digits()를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, else False, 0으로 변환\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 데이터 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균현항 레이블 데이터 분포도 확인\n",
    "print('레이블 데이터 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fake_clf = MyFakeClassifier()\n",
    "fake_clf.fit(X_train, y_train)\n",
    "fake_pred = fake_clf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test, fake_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 predict()의 결과를 np.zeors()로 모두 0 값으로 반환함에도 불구하고 450개의 테스트 데이터 세트에 수행한 예측 정확도는 90%이다  \n",
    "단지 모든 것을 0으로만 예측해도 MyFakeClassifier의 정확도가 90%로 유수의 ML 알고리즘과 어깨를 겨룰 수 있다는건 말이 안되는 결과이다  \n",
    "  \n",
    "  \n",
    "  \n",
    "이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용되서는 안된다  \n",
    "정확도가 가지는 분류 평가 지표로서 이러한 한계점을 극복하기 위해 여러 가지 분류 지표와 함께 적용해야 한다  \n",
    "Ex) 오차행렬(Confusion Matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
